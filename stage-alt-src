#!/usr/bin/python

import ConfigParser
import datetime
import hashlib
import logging
import koji
from optparse import OptionParser
import os
import os.path
import re
import rpm
import shutil
import smtplib
import subprocess
import sys
import tempfile
import traceback



'''
Given an srpm and product, stage for alt-src release
'''


def _(args):
    """Stub function for translation"""
    return args


def get_options():
    """process options from command line"""

    usage = _("%prog [options] branch srpm")
    parser = OptionParser(usage=usage)
    parser.add_option("-c", "--config", dest="cfile", default='/etc/altsrc.conf',
                      help=_("use alternate configuration file"), metavar="FILE")
    parser.add_option("-v", "--verbose", action="store_true", default=False,
                      help=_("be more verbose"))
    parser.add_option("-q", "--quiet", action="store_true", default=False,
                      help=_("be less verbose"))
    parser.add_option("-d", "--debug", action="store_true", default=False,
                      help=_("show debug output"))
    parser.add_option("--force", action="store_true", default=False,
                      help=_("force operation"))
    parser.add_option("--push", action="store_true", default=False,
                      help=_("push staged sources"))
    parser.add_option("-o", "--option", dest="copts", action="append", metavar="OPT=VALUE",
                      help=_("set config option"))
    (options, args) = parser.parse_args()

    options.branch = args[0]
    options.source = args[1]

    options.config = get_config(options.cfile, options.copts)

    return options


config_defaults = {
    'stagedir' : '/srv/cache/stage',
    'gitdir' : '/srv/git',
    'rulesdir' : '/var/lib/altsrc/rules',
    'lookaside' : '/srv/cache/lookaside',
    'git_push_url' : '/srv/git/pushtest/%(package)s.git',
    'lookaside_rsync_dest' : '/srv/cache/lookaside2',
    'log_level' : 'WARN',
    'log_file' : None,
    'log_format' : '%(asctime)s [%(levelname)s] %(message)s',
    'whitelist' : '',
    'blacklist' : '',
    'changelog_user' : 'sources@centos.org',
    'smtp_enabled' : True,
    'smtp_host' : 'localhost',
    #'smtp_host' : 'smtp.corp.redhat.com',
    'smtp_from' : 'Alt Source Stager <altsrc@redhat.com>',
    'smtp_to' : 'mike',
    'smtp_log_to' : '',
}

config_int_opts = set([])
config_bool_opts = set(['smtp_enabled'])

def get_config(cfile, overrides):
    if not os.access(cfile, os.F_OK):
        die("Missing config file: %s" % cfile)
    cp = ConfigParser.RawConfigParser()
    cp.read(cfile)
    if not cp.has_section('altsrc'):
        die("Configuration file missing [altsrc] section: %s" % cfile)

    #apply overrides from command line
    overrides = overrides or []
    for opt in overrides:
        parts = opt.split("=", 1)
        if len(parts) != 2:
            die('Invalid option specification: %s\nUse OPT=VALUE' % opt)
        key, value = parts
        cp.set('altsrc', key, value)

    #generate config dictionary
    config = dict(config_defaults)  #copy
    for key in cp.options('altsrc'):
        if key in config_int_opts:
            config[key] = cp.getint('altsrc', key)
        elif key in config_bool_opts:
            config[key] = cp.getboolean('altsrc', key)
        else:
            config[key] = cp.get('altsrc', key)

    #sanity checks
    if not os.path.isdir(config['stagedir']):
        die("No such directory: %s" % config['stagedir'])

    return config



class SpecFile(object):
    '''
        Spec manipulation functions
        Based on similar class from python-rpmpatch
        https://cdcvs.fnal.gov/redmine/projects/python-rpmpatch/
    '''

    def __init__(self, specfile, changelog_user):
        '''
            Read in the specfile and setup our environment
        '''
        self.logger = logging.getLogger("altsrc")
        self.specfile = specfile

        self.changelog_user = changelog_user
        self.changelog = {}

        self.changelog_done = False

        self.text = None

        _fd = open(self.specfile, 'r')
        self.text = _fd.read()
        _fd.close()

        basedir = os.path.dirname(self.specfile)
        self.basedir = basedir
        self.sourcesdir = os.path.abspath(basedir + '/../SOURCES/')
        if os.path.isfile(self.sourcesdir + '/' + self.specfile):
            os.remove(self.sourcesdir + '/' + self.specfile)
        #shutil.copy2(self.specfile, self.sourcesdir)

    def __del__(self):
        '''
            Make sure to save changes
        '''
        if self.text != None:
            self.save()

    def run_re(self, regex_match, regex_replace, changelog):
        '''
            Run a regex against the specfile
        '''
        self.text = re.sub(regex_match, regex_replace, self.text)

        regname = regex_match + ' => ' + regex_replace

        self.changelog['Ran Regex: ' + regname] = changelog

        return True

    def apply_specfile_diff(self, spec_patch, changelog):
        '''
            For any actual changes to the specfile you will need to generate
            a nice simple unified diff summarizing your changes.  The diff will
            be automatically added to the SRPM as a 'SOURCE' file so that you
            can easily review your changes in the future.

            This is not pure python. http://bugs.python.org/issue2057

            Your patch must have a stripe of '0' or things wont work right.
            Rather than accounting for all use cases I'm just forcing a simple
            one so you will have to deal with it.
        '''
        tempdir = tempfile.mkdtemp()
        specname = os.path.basename(self.specfile)
        _fd = open(tempdir + '/' + specname, 'w')
        _fd.write(self.text)
        _fd.close()

        _fd = open(spec_patch, 'r')

        thisdir = os.getcwd()
        os.chdir(tempdir)
        code = subprocess.call(['patch' , '-p0'], stdin=_fd,
                               stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                               shell=True)
        _fd.close()
        if code != 0:
            raise RuntimeError(code, "Spec diff failed")

        _fd = open(tempdir + '/' + specname, 'r')
        self.text = _fd.read()
        _fd.close()

        self.add_source(spec_patch, None, changelog=changelog)

        os.chdir(thisdir)
        shutil.rmtree(tempdir)

        return True

    def add_patch(self, patchfile, patchstripe, patchnum, changelog):
        '''
            This will add a given patch into the rpm package.  You must
            specify the patch stripe (the 1 from -p1).

            A unique number is required for the patchnum.
            You can specify one or set it to 'None' and a somewhat random,
            though unique, number will be created for you.

            You must provide a changelog reason for this modification.
        '''
        patch_re = '([pP]atch(\d*):\s+(\S+))'
        matches = re.findall(patch_re, self.text)
        # if we are making a number up
        if patchnum == None:
            # if there are no existing patches we start at 0, else at 1
            if not matches:
                patchnum_list = [ 0 ]
            else:
                patchnum_list = [ 1 ]

            # put all the numbers in a list
            for match in matches:
                if match[1]:
                    patchnum_list.append(int(match[1]))

        # find the biggest num and + 1
        patchnum = (max(patchnum_list) + 1)

        patchname = os.path.basename(patchfile)
        if os.path.isfile(self.basedir + '/../SOURCES/' + patchname):
            os.remove(self.basedir + '/../SOURCES/' + patchname)
        self.logger.debug("Copy %s -> %s", patchfile, self.sourcesdir)
        shutil.copy2(patchfile, self.sourcesdir)
        entry = "\nPatch" + str(patchnum) + ":\t" + patchname

        matches = re.findall(patch_re, self.text)
        if matches:
            patch_entry = matches[-1][0]
        else:
            namematch = re.findall('(\s*[nN]ame:\s+.*)', self.text)
            patch_entry = namematch[0]

        self.text = self.text.replace(patch_entry, patch_entry + entry)

        entry = "\n%patch" + str(patchnum) + ' -p' + str(patchstripe)
        patch_re = '(%patch\d+\s+-p\d.*)'
        matches = re.findall(patch_re, self.text)
        if matches:
            patch_entry = matches[-1]
        else:
            setup_re = '(%setup.*)'
            matches = re.findall(setup_re, self.text)
            patch_entry = matches[0]

        self.text = self.text.replace(patch_entry, patch_entry + entry)

        self.changelog['Added Patch: ' + patchname] = changelog

        return (patchnum, patchname)

    def rm_patch(self, patchname, patchnum, changelog):
        '''
            Prevent a given patch from being applied to the rpm package.

            You can describe the patch by name or by number, but you
            must pick one!  Set the other to 'None'

            You must provide a changelog reason for this modification.
        '''

        if patchname != None:
            patch_re = '(\s*[pP]atch(\d+):\s+(' + patchname + ')\n)'
        elif patchnum != None:
            patch_re = '(\s*[pP]atch(' + str(patchnum) + '):\s+(\S+?)\s+?)'
        else:
            raise ValueError('You must specify something I can use here')

        matches = re.findall(patch_re, self.text)
        self.text = self.text.replace(matches[0][0], '\n')

        patchnum = matches[0][1]
        patchname = matches[0][2]

        patch_re = '(%patch' + patchnum + '.+?\n)'
        match_patch = re.findall(patch_re, self.text)
        self.text = self.text.replace(match_patch[0], '\n')

        self.changelog['Removed Patch: ' + patchname] = changelog

        return (patchnum, patchname)

    def add_source(self, sourcefile, sourcenum, changelog):
        '''
            Add a source file to the rpm spec.

            A unique number is required for the sourcenum.
            You can specify one or set it to 'None' and a somewhat random,
            though unique, number will be created for you.

            You must provide a changelog reason for this modification.
        '''
        source_re = '([sS]ource(\d*):\s+(\S+))'
        matches = re.findall(source_re, self.text)
        # if we are making a number up
        if sourcenum == None:
            # if there are no existing sources we start at 0, else at 1
            if not matches:
                sourcenum_list = [ 0 ]
            else:
                sourcenum_list = [ 1 ]

            # put all the numbers in a list
            for match in matches:
                if match[1]:
                    sourcenum_list.append(int(match[1]))

        # find the biggest num and + 1
        sourcenum = (max(sourcenum_list) + 1)

        sourcename = os.path.basename(sourcefile)
        if os.path.isfile(self.basedir + '/../SOURCES/' + sourcename):
            os.remove(self.basedir + '/../SOURCES/' + sourcename)
        self.logger.debug("Copy %s -> %s", sourcefile, self.sourcesdir)
        shutil.copy2(sourcefile, self.sourcesdir)
        entry = "\nSource" + str(sourcenum) + ":\t" + sourcename

        matches = re.findall(source_re, self.text)
        if matches:
            source_entry = matches[-1][0]
        else:
            namematch = re.findall('(\s*[nN]ame:\s+.+)', self.text)
            source_entry = namematch[0]

        self.text = self.text.replace(source_entry, source_entry + entry)

        self.changelog['Added Source: ' + sourcename] = changelog

        return (sourcenum, sourcename)

    def __add_changelog(self):
        '''
            Record the changes in the changelog
        '''
        if self.changelog_done == True:
            return
        now = datetime.datetime.now().strftime('%a %b %d %Y ')
        changelog_text = '%changelog\n* ' + now + self.changelog_user + '\n'
        for action in self.changelog.keys():
            changelog_text = changelog_text + '- ' + action + '\n'
            changelog_text = changelog_text + '-->  ' + self.changelog[action]
            changelog_text = changelog_text + '\n'

        changelog_text = changelog_text + '\n'

        self.text = self.text.replace('%changelog\n', changelog_text)

        self.changelog_done = True

        return True

    def save(self):
        '''
            Write out the specfile with changes
        '''
        self.__add_changelog()
        _fd = open(self.specfile, 'w')
        _fd.write(self.text)
        _fd.close()

        return True


class StageError(Exception):
    """Our base error class"""
    pass

class StartupError(StageError):
    """Raised when an error happens very early"""
    pass

class CommandError(StageError):
    """Raised when a command we run fails"""

class FilterError(StageError):
    pass

class SanityError(StageError):
    pass

class ConfigError(StageError):
    pass




class Stager(object):

    def __init__(self, options):
        self.options = options
        self.logger = logging.getLogger("altsrc")
        self.srpm = options.source
        #TODO - support pulling srpm from Brew
        if not os.path.isfile(self.srpm):
            raise StartupError, "No such file: %s" % self.srpm
        self.logfile = None

    def run(self):
        self.read_srpm()
        self.check_package()
        self.make_workdir()
        self.setup_logfile()
        self.sync_repo()
        self.setup_checkout()
        self.import_srpm()
        self.debrand()
        self.remake_srpm()
        self.notify()
        #TODO - write runtime data to workdir so publication script knows what to do


    def log_cmd(self, cmd, logfile=None, fatal=True, **kwargs):
        """Run command and log output if able"""
        self.logger.info('Running command: %s', ' '.join(cmd))
        if logfile:
            kwargs.setdefault('stdout', self.logfile)
            kwargs.setdefault('stderr', subprocess.STDOUT)
            kwargs.setdefault('close_fds', True)
        elif self.logfile:
            self.logfile.flush()
            kwargs.setdefault('stdout', self.logfile)
            kwargs.setdefault('stderr', subprocess.STDOUT)
            kwargs.setdefault('close_fds', True)
        proc = subprocess.Popen(cmd, **kwargs)
        ret = proc.wait()
        if ret:
            if fatal:
                raise CommandError, "command failed: %r" % cmd
            #otherwise
            self.logger.warn("Command failed: %r" % cmd)
        return ret


    def read_srpm(self):
        self.logger.info('Reading source rpm: %s', self.srpm)
        h = koji.get_rpm_header(self.srpm)
        self.headers = h
        if h[rpm.RPMTAG_SOURCEPACKAGE] != 1:
            raise InputError, "%s is not a source package" % self.srpm
        data = koji.get_header_fields(h, ['name','version','release'])
        self.nvr = "%(name)s-%(version)s-%(release)s" % data
        self.package = data['name']
        self.version = data['version']

    def check_package(self):
        """Check whitelist/blacklist and load any package rules"""

        whitelist = self.options.config['whitelist'].split()
        if whitelist:
            whitelisted = koji.util.multi_fnmatch(self.package, whitelist)
        else:
            whitelisted = False
        if not whitelisted:
            blacklist = self.options.config['blacklist'].split()
            if blacklist and koji.util.multi_fnmatch(self.package, blacklist):
                raise FilterError, 'Blacklisted package: %s' % self.package


    def get_workdir(self):
        letter = self.package[0]
        if not letter.isalpha():
            letter = "_"
        parts = [
            os.path.join(self.options.config['stagedir']),
            letter,
            self.package,
            self.nvr,
        ]
        return os.path.join(*parts)


    def make_workdir(self):
        dirname = self.get_workdir()
        self.logger.info('Creating working directory: %s', dirname)
        if os.path.islink(dirname):
            raise SanityError, "%s is a symlink" % dirname
        elif os.path.isdir(dirname):
            # TODO - more sanity checks
            if self.options.force:
                self.logger.warn("Overwriting existing workdir: %s",  dirname)
                # TODO - back up first
                koji.util.rmtree(dirname)
            else:
                raise SanityError, "Work directory %s directory exists, use --force to overwrite." % dirname
        elif os.path.exists(dirname):
            raise SanityError, "%s exists and is not a directory" % dirname
        koji.ensuredir(dirname)
        self.workdir = dirname


    def setup_logfile(self):
        self.logfile = file(os.path.join(self.workdir, 'stage.log'), 'w')
        handler = logging.StreamHandler(self.logfile)
        handler.setFormatter(logging.Formatter(self.options.config['log_format']))
        handler.setLevel(logging.DEBUG)
        self.logger.addHandler(handler)


    def sync_repo(self):
        """Sync the primary (bare) git repo from the (local) master"""

        repo = os.path.join(self.options.config['gitdir'], "%s.git" % self.package)

        if not os.path.exists(repo):
            self.init_repo()
            return

        self.logger.info('Syncing primary repo: %s', repo)
        cmd = ['git', 'fetch', '-v', 'origin', '+refs/*:refs/*']
        self.log_cmd(cmd, cwd=repo)

        # TODO - add sanity checks


    def init_repo(self):
        """Initialize a new repo"""
        pass
        #TODO


    def setup_checkout(self):
        """Setup our working checkout"""

        src = os.path.join(self.options.config['gitdir'], "%s.git" % self.package)
        dst = os.path.join(self.workdir, "checkout")
        self.checkout = dst
        self.logger.info('Setting up working checkout: %s', dst)
        cmd = ['git', 'clone', '--local', '-v', src, dst]
        self.log_cmd(cmd, cwd=self.workdir)

        #create and checkout our staging branch
        branchname = "altsrc-stage-%s" % self.options.branch
        self.branchname = branchname
        base = 'refs/remotes/origin/%s' % self.options.branch
        self.logger.info('Setting up staging branch: %s', branchname)
        cmd = ['git', 'show-ref', '--verify', base]
        rv = self.log_cmd(cmd, cwd=dst, fatal=False)
        if rv:
            self.logger.warn('Base branch %s missing, staging on an orphan branch', self.options.branch)
            cmd = ['git', 'checkout', '--orphan', branchname]
            self.log_cmd(cmd, cwd=dst)
            cmd = ['git', 'rm', '-rf', '.']
            self.log_cmd(cmd, cwd=dst)
            # add a commit so we can tag the start point
            cmd = ['git', 'commit', '--allow-empty', '-m', 'new orphan branch']
            self.log_cmd(cmd, cwd=dst)
        else:
            cmd = ['git', 'checkout', '-b', branchname, base]
            self.log_cmd(cmd, cwd=dst)

        #tag our starting point
        tagname = "altsrc-start-%s" % self.options.branch
        cmd = ['git', 'tag', tagname, branchname]
        self.log_cmd(cmd, cwd=self.checkout)


    # file extensions that are automatically placed in lookaside
    # (should all be lower case)
    UPLOAD_EXTS = [
        'tar', 'gz', 'bz2', 'lzma', 'xz', 'z', 'zip', 'tff',
        'bin', 'tbz', 'tbz2', 'tgz', 'tlz', 'txz', 'pdf', 'rpm',
        'jar', 'war', 'db', 'cpio', 'jisp', 'egg', 'gem', 'iso',
        ]

    # file extensions that are automatically included in repo
    # (should all be lower case)
    INCLUDE_EXTS = [
        'spec', 'patch', 'diff',
        'html', 'txt', 'init', 'conf', 'sh',
        ]

    def for_lookaside(self, path):
        """Determine if a file should go to the lookaside cache

        Return True if file should go to the lookaside
        """
        # there are varying heuristics for what to place in the lookaside
        # Fedora/pyrpkg decides based on extension
        # Centos/nazar decides based on output of the file utility
        # We're using a hybrid approach
        ext = path.rsplit('.')[-1].lower()
        if ext in self.INCLUDE_EXTS:
            return False
        if ext in self.UPLOAD_EXTS:
            return True
        st = os.stat(path)
        if st.st_size < 1024:
            # the UPLOAD_EXTS check should catch most of what we want in
            # the lookaside, so we'll just include anything small
            return False
        #lastly, see what the file utility says
        cmd = ['file', '--brief', path]
        # XXX should we use --mime instead?
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True)
        output = proc.communicate()[0]
        if proc.wait():
            #nonfatal
            self.logger.warn("command failed: %r" % cmd)
            self.logger.warn("output was: %r" % output)
            return False
        self.logger.debug("Source file %s: %s", path, output)
        return output.find('text') == -1

    def import_srpm(self):
        """Import our srpm on the specified branch"""

        #explode our srpm
        dst = self.checkout
        wipe_git_dir(dst)
        self.logfile.flush()
        explode_srpm(self.srpm, dst, logfile=self.logfile)

        #figure out which sources go to the lookaside
        to_move = []
        sourcedir = os.path.join(dst, 'SOURCES')
        for fn in os.listdir(sourcedir):
            path = os.path.join(sourcedir, fn)
            if self.for_lookaside(path):
                to_move.append(fn)

        # move files to lookaside
        if to_move:
            meta = file(os.path.join(dst, ".%s.metadata" % self.package), 'w')
            gitignore = file(os.path.join(dst, ".gitignore"), 'w')
        for fn in to_move:
            path = os.path.join(sourcedir, fn)
            csum = hashlib.sha1()
            # XXX should we move to something stronger?
            fo = file(path, 'rb')
            chunk = 'IGNORE ME!'
            while chunk:
                chunk = fo.read(8192)
                csum.update(chunk)
            fo.close()
            digest = csum.hexdigest()
            dirname = os.path.join(self.options.config['lookaside'], self.package, self.options.branch)
            # XXX - using Centos/nazar path for now, may need to change
            lpath = os.path.join(dirname, digest)
            if not os.path.isfile(lpath):
                koji.ensuredir(dirname)
                self.logger.info('Copying source file to lookaside: %s -> %s', fn, lpath)
                shutil.copy2(path, lpath)
            else:
                # we appear to already have it
                st1 = os.stat(path)
                st2 = os.stat(lpath)
                if st1.st_size != st2.st_size:
                    self.logger.error("Possibly corrupt lookaside entry: %s", lpath)
                    self.logger.error("Size: %s, but current matching source is %s", st1.st_size, st2.st_size)
                    raise SanityError, "Lookaside size mismatch"
                # TODO - more sanity checks
                self.logger.info('Skipping source, already in digest: %s', fn)
                #os.unlink(path)
            # write metadata file
            meta.write("%s %s\n" % (digest, fn))
            # write .gitignore
            gitignore.write('SOURCES/%s\n' % fn)
        if to_move:
            meta.close()
            gitignore.close()

        cmd = ['git', 'add', '-A', '.']
        self.log_cmd(cmd, cwd=dst)


        cmd = ['git', 'commit', '-m', 'import %s' % self.nvr]
        self.log_cmd(cmd, cwd=dst)


    def find_spec(self):
        """Locate specfile in checkout"""
        specdir = os.path.join(self.checkout, 'SPECS')

        #first look for $package.spec
        path = os.path.join(specdir, self.package + '.spec')
        if os.path.isfile(path):
            return path

        #otherwise
        for fn in os.listdir(specdir):
            if fn.endswith('.spec'):
                return os.path.join(specdir, fn)

        raise SanityError, 'No spec file in checkout: %s' % self.checkout


    def debrand(self):
        """Apply debranding rules"""
        #search for applicable rules

        cp = ConfigParser.RawConfigParser()
        for name in 'altsrc-global', self.package:
            cfile = os.path.join(self.options.config['rulesdir'], name + '.cfg')
            if not os.access(cfile, os.F_OK):
                continue
            self.logger.info('Loading rules from %s', cfile)
            cp.read(cfile)

        # order rules
        rules = []
        for section in cp.sections():
            parts = section.split(None, 1)
            if len(parts) < 2:
                continue
            rtype, key = parts
            rules.append((key, rtype, section))
        rules.sort()

        if not rules:
            self.logger.info('No rules found')
            return

        # apply rules
        for key, rtype, section in rules:
            handler = 'rule_handler_%s' % rtype
            if not hasattr(self, handler):
                raise ConfigError, "No handler for rule type %s" % rtype
            data = dict(cp.items(section))
            if 'enabled' in data:
                enabled = data['enabled'].lower().strip()
                if enabled in ('no', 'false', '0'):
                    self.logger.info('Skipping disabled rule: %s', section)
                    continue
            if 'on_package' in data:
                patterns = data['on_package'].split()
                if not koji.util.multi_fnmatch(self.package, patterns):
                    self.logger.debug('Skipping rule due to package filter: %s', section)
                    continue
            if 'on_version' in data:
                patterns = data['on_version'].split()
                if not koji.util.multi_fnmatch(self.version, patterns):
                    self.logger.debug('Skipping rule due to version filter: %s', section)
                    continue
            if 'on_branch' in data:
                patterns = data['on_branch'].split()
                if not koji.util.multi_fnmatch(self.options.branch, patterns):
                    self.logger.debug('Skipping rule due to branch filter: %s', section)
                    continue
            self.logger.info("Applying rule: %s", section)
            getattr(self, handler)(data)
            # TODO - check result

        # add and commit changes
        cmd = ['git', 'add', '-A', '.']
        self.log_cmd(cmd, cwd=self.checkout)

        # check that we actually have something to commit
        cmd = ['git', 'diff', '--cached', '--name-only']
        proc = subprocess.Popen(cmd, cwd=self.checkout, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True)
        output = proc.communicate()[0]
        rv = proc.wait()
        if not output:
            raise SanityError, "Debranding rules made no changes"
            #XXX raising an error is probably not the right thing here

        cmd = ['git', 'commit', '-m', 'debranding changes']
        self.log_cmd(cmd, cwd=self.checkout)


    def rule_handler_spec(self, data):
        """Patch the spec file"""

        spec = SpecFile(self.find_spec(), self.options.config['changelog_user'])

        changelog = data.get('changelog')
        fn = data['patch']
        patch = os.path.join(self.options.config['rulesdir'], fn)
        spec.apply_specfile_diff(patch, changelog)

    def rule_handler_re(self, data):
        """Apply a regex substitution to the spec file"""

        spec = SpecFile(self.find_spec(), self.options.config['changelog_user'])

        changelog = data.get('changelog')
        spec.run_re(data['match'], data['replace'], changelog)

    def rule_handler_patch(self, data):
        """Add or remove a patch in the spec file"""

        spec = SpecFile(self.find_spec(), self.options.config['changelog_user'])

        method = data['method'].lower()
        changelog = data.get('changelog')
        num = data.get('num')
        if method == 'add':
            name = data['patch']
            stripe = data['stripe']
            spec.add_patch(name, stripe, num, changelog)

        elif method == 'del':
            if 'patch' in data:
                name = os.path.basename(data['patch'])
            else:
                name = None

            # XXX I guess this is a common rpmpatch config typo?
            if num == name:
                raise ConfigError, 'Bad patch section in config'

            return spec.rm_patch(name, num, changelog)


    def rule_handler_source(self, data):
        """Add a source to the specfile"""

        spec = SpecFile(self.find_spec(), self.options.config['changelog_user'])

        changelog = data.get('changelog')
        method = data['method'].lower()
        num = data.get('num')
        if method == 'add':
            thisfile = data['source']
            spec.add_source(thisfile, num, changelog)

        #XXX - no other methods??
        else:
            raise ConfigError, 'Bad source section in config file'

    def rule_handler_script(self, data):
        """Run an arbitary script"""
        fn = data['script']
        script = os.path.join(self.options.config['rulesdir'], fn)
        if not os.path.isfile(script):
            raise ConfigError, 'Script missing: %s' % script

        cmd = [script, self.workdir, self.find_spec()]
        self.log_cmd(cmd, cwd=self.workdir)

    def remake_srpm(self):
        """Remake the srpm"""
        # This is mainly a test
        cmd = ['rpmbuild', '-bs',
                '--define', '_topdir %s' % self.checkout,
                '--define', '_srcrpmdir %s' % self.workdir,
                '--define', 'dist .TEST',
                self.find_spec()]
        self.log_cmd(cmd, cwd=self.workdir)


    def notify(self):
        subject = 'Successfully staged %s' % self.nvr
        body = """\
Staging completed for %(nvr)s.

Working directory: %(workdir)s
""" % vars(self)
        body = body % locals()
        #TODO : be more informative
        self.send_email_notice('info', subject, body)


    def handle_error(self):
        """Handle an exception. Called from top level."""
        tb = ''.join(traceback.format_exception(*sys.exc_info()))
        self.logger.exception('Staging failed')
        cls, err = sys.exc_info()[:2]
        msg = ''.join(traceback.format_exception_only(cls, err))
        self.logger.warning("Sending error email")
        nvr = self.nvr or "UNKNOWN"
        subject = 'Error staging %s' % nvr
        body = """\
Staging failed for %(nvr)s.

%(tb)s
"""
        body = body % locals()
        #TODO : be more informative

        self.send_email_notice('error', subject, body)


    def send_email_notice(self, level, subject, body, extra_headers=None):
        if not self.options.config['smtp_enabled']:
            self.logger.warning("SMTP disabled. Skipping email notification.")
            return
        if level == 'info':
            recipients = self.options.config['smtp_log_to']
        else:
            recipients = self.options.config['smtp_to']
        if not recipients:
            self.logger.warning("No recipients configured. Skipping email notification.")
            return
        package = self.package or "UNKNOWN"
        headers = [
            ('From', self.options.config['smtp_from']),
            ('Subject', subject),
            ('To', recipients),
            ('X-altsrc-package', package),
        ]
        if extra_headers:
            headers.extend(extra_headers)

        head = "\n".join(["%s: %s" % (k,v) for k,v in headers])
        message = "%s\n\n%s" % (head, body)
        message.replace('\n', '\r\n')
        message = koji.fixEncoding(message)
        server = smtplib.SMTP(self.options.config['smtp_host'])
        server.sendmail(self.options.config['smtp_from'], self.options.config['smtp_to'], message)
        server.quit()


class Pusher(Stager):
    #XXX this inheritance is wrong, but for now it is a quick way to get going

    def run(self):
        self.read_srpm()
        self.check_package()
        self.check_workdir()
        self.setup_logfile()
        self.push_lookaside()
        self.push_git()
        self.notify()


    def check_workdir(self):
        dirname = self.get_workdir()
        self.logger.info('Checking working directory: %s', dirname)
        if os.path.islink(dirname):
            raise SanityError, "%s is a symlink" % dirname
        if not os.path.isdir(dirname):
            # TODO - option to go ahead and stage if needed
            raise SanityError, "Not staged. No such directory: %s" % dirname
        self.workdir = dirname
        # TODO - load info left by stage run
        self.checkout = os.path.join(self.workdir, "checkout")



    def setup_logfile(self):
        self.logfile = file(os.path.join(self.workdir, 'push.log'), 'w')
        handler = logging.StreamHandler(self.logfile)
        handler.setFormatter(logging.Formatter(self.options.config['log_format']))
        handler.setLevel(logging.DEBUG)
        self.logger.addHandler(handler)


    def push_git(self):
        """Get our checkout ready for the public push"""
        # check out the stage branch
        stage = "altsrc-stage-%s" % self.options.branch
        cmd = ['git', 'checkout', stage]
        self.log_cmd(cmd, cwd=self.checkout)

        # fetch from public remote
        params = {'package': self.package }  #XXX anything else?
        git_url =  self.options.config['git_push_url'] % params
        pushbranch = "altsrc-push-%s" % self.options.branch
        # see if remote has it
        cmd = ['git', 'ls-remote', git_url, "refs/heads/%s" % self.options.branch]
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=self.logfile, close_fds=True)
        output = proc.communicate()[0]
        rv = proc.wait()
        if rv:
            #error talking to remote. Could be that that repo does not exist, or could be a network error
            pass #XXX
            #TODO attempt to init repo on remote
        new_branch = False
        if not output:
            # XXX we should check the output more thoroughly
            self.logger.warning("Branch missing on remote: %s", self.options.branch)
            new_branch = True
        else:
            cmd = ['git', 'fetch', '-v', git_url, "+%s:%s" % (self.options.branch, pushbranch)]
            self.log_cmd(cmd, cwd=self.checkout)

        # now force sync the pushbranch contents to match the stage in a single commit
        if new_branch:
            cmd = ['git', 'checkout', '--orphan', pushbranch]
            # XXX is an orphan branch the right thing?
        else:
            cmd = ['git', 'checkout', pushbranch]
        self.log_cmd(cmd, cwd=self.checkout)
        cmd = ['git', 'rm', '-rf', '.']
        self.log_cmd(cmd, cwd=self.checkout)
        cmd = ['git', 'checkout', stage, '--', '.']
        self.log_cmd(cmd, cwd=self.checkout)

        # check that we actually have something to commit
        cmd = ['git', 'diff', '--cached', '--name-only']
        proc = subprocess.Popen(cmd, cwd=self.checkout, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True)
        output = proc.communicate()[0]
        rv = proc.wait()
        if not output:
            raise SanityError, "Nothing to commit. Already pushed?"
        # if we're called again for some reason the commit will fail
        # detect this and give a nicer error
        cmd = ['git', 'commit', '-m', 'import %s' % self.nvr]
        #XXX need a better commit message
        self.log_cmd(cmd, cwd=self.checkout)

        # ...and push
        cmd = ['git', 'push', git_url, "%s:%s" % (pushbranch, self.options.branch)]
        self.log_cmd(cmd, cwd=self.checkout)

        #TODO retry loop

    def push_lookaside(self):
        meta = file(os.path.join(self.checkout, ".%s.metadata" % self.package), 'r')
        for line in meta.readlines():
            line = line.strip()
            digest, fn = line.split(None, 1)
            self.push_lookaside_file(digest, fn)

    def push_lookaside_file(self, digest, fn):
        relpath = os.path.join(self.package, self.options.branch, digest)
        cmd = ['rsync', '-ivpt', '--relative', relpath, self.options.config['lookaside_rsync_dest']]
        # --relative option preserves the relative path from the command line
        # this is a way to ensure we create the necessary subdirs
        self.log_cmd(cmd, cwd=self.options.config['lookaside'])


    def notify(self):
        subject = 'Successfully pushed %s' % self.nvr
        body = """\
Push completed for %(nvr)s.

Working directory: %(workdir)s
""" % vars(self)
        body = body % locals()
        #TODO : be more informative
        self.send_email_notice('info', subject, body)



def explode_srpm(srpm, destdir=None, logfile=None):
    # explode our srpm to the given directory
    h = koji.get_rpm_header(srpm)
    if h[rpm.RPMTAG_SOURCEPACKAGE] != 1:
        # we checked this earlier, but since we're about to rpm -i it,
        # let's check again
        raise SanityError, "%s is not a source package" % srpm
    if destdir is None:
        destdir = os.getcwd()
    else:
        destdir = os.path.abspath(destdir)
        koji.ensuredir(destdir)
    cmd = ['rpm', '--nosignature', '-i', '--define', '_topdir %s' % destdir, srpm]
    #print "Running: %r" % cmd
    popts = {'close_fds':True}
    if logfile:
        popts['stdout'] = logfile
        popts['stderr'] = subprocess.STDOUT
    proc = subprocess.Popen(cmd, **popts)
    ret = proc.wait()
    if ret:
        raise CommandError, "command failed: %r" % cmd


def wipe_git_dir(dirname):
    for fn in os.listdir(dirname):
        if fn == '.git':
            continue
        path = os.path.join(dirname, fn)
        if os.path.isdir(path):
            koji.rmtree(path)
        else:
            os.unlink(path)


def die(msg):
    print msg
    sys.exit(1)


def setup_logging(options):
    logger = logging.getLogger("altsrc")
    handler = logging.StreamHandler(sys.stderr)
    handler.setFormatter(logging.Formatter(options.config['log_format']))
    handler.setLevel(logging.DEBUG)
    logger.addHandler(handler)
    if options.config['log_file']:
        handler = logging.FileHandler(options.config['log_file'])
        handler.setFormatter(logging.Formatter(options.config['log_format']))
        handler.setLevel(logging.DEBUG)
        logger.addHandler(handler)
    level = options.config['log_level']
    if options.debug:
        level = 'DEBUG'
    elif options.verbose:
        level = 'INFO'
    elif options.quiet:
        level = 'ERROR'
    lvl = getattr(logging, level, None)
    if lvl is None:
        die("Invalid log level: %s" % options.config['log_level'])
    logger.setLevel(lvl)
    # TODO - setup koji's logger?
    return logger


def main():
    options = get_options()
    logger = setup_logging(options)
    if options.push:
        task = Pusher(options)
    else:
        task = Stager(options)
    try:
        task.run()
    except (SystemExit, KeyboardInterrupt), e:
        msg = ''.join(traceback.format_exception_only(*sys.exc_info()[:2]))
        logger.warn("Exiting (%s)", msg)
        sys.exit(1)
    except Exception:
        task.handle_error()
        sys.exit(2)

if __name__ == '__main__':
    main()

# the end
